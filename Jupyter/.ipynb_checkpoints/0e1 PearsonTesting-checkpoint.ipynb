{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/home/scidb/HeartRatePatterns/Python\"))\n",
    "from LogisticRegresion import ajustLogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectMatrix(withPearson,dbname=\"mimic\") :\n",
    "    conn = psycopg2.connect(\"dbname=\"+dbname)\n",
    "    cur = conn.cursor()\n",
    "    select_stament = (\"SELECT m.subject_id,m.word,m.counting,s.isalive \"\n",
    "                      \" FROM matrix m LEFT JOIN subjectwords s ON m.subject_id=s.subject_id\"\n",
    "    )\n",
    "    if withPearson:\n",
    "        select_stament = select_stament+\" WHERE m.word in (select word from wordspearson where p1>0.01) \"\n",
    "    cur.execute(select_stament)\n",
    "    select = []\n",
    "    for row in cur :\n",
    "        select.append((row))\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertMatrix(withPearson=False) :\n",
    "    labels = ['subject_id', 'Word', 'Counting','isAlive']\n",
    "    df = pd.DataFrame.from_records(selectMatrix(withPearson), columns=labels)\n",
    "    print(len(df))\n",
    "    return pd.pivot_table(df,index=[\"subject_id\",\"isAlive\"],columns=[\"Word\"],values=[\"Counting\"],\n",
    "                       aggfunc={\"Counting\":[np.sum]},fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePearson(pearson,dbname=\"mimic\") :\n",
    "    conn = psycopg2.connect(\"dbname=\"+dbname)\n",
    "    cur = conn.cursor()\n",
    "    insert_statement=('INSERT INTO wordspearson(word,p1,p2)'\n",
    "                      ' SELECT unnest( %(word)s ) ,'\n",
    "                      ' unnest( %(p1)s) ,'\n",
    "                      ' unnest( %(p2)s)')\n",
    "    word=[r['word'] for r in pearson]\n",
    "    p1=[r['p1'] for r in pearson]\n",
    "    p2=[r['p2'] for r in pearson]\n",
    "#    print(cur.mogrify(insert_statement,locals()))\n",
    "    cur.execute(insert_statement,locals())\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961128\n"
     ]
    }
   ],
   "source": [
    "table = convertMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = table.index.labels[1].tolist()\n",
    "patients = table.values\n",
    "columns = list(table.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonList = []\n",
    "for i in range(len(columns)):\n",
    "    pearson = pearsonr(patients[:,i],survived)\n",
    "    pearsonList.append({'word':columns[i][2],'p1':pearson[0],'p2':pearson[1]})\n",
    "savePearson(pearsonList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34946\n"
     ]
    }
   ],
   "source": [
    "table = convertMatrix(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = table.index.labels[1].tolist()\n",
    "patients = table.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_train, patients_test,survived_train, survived_test = train_test_split(patients,survived,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 218)\n",
      "(400, 218)\n",
      "(100, 218)\n"
     ]
    }
   ],
   "source": [
    "print(table.shape)\n",
    "print(patients_train.shape)\n",
    "print(patients_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/svm/base.py:898: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/svm/base.py:898: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV averages for values [0.0001, 0.001, 0.01, 0.1, 1, 10] are:[ 0.77849832  0.74358607  0.74194313  0.73258437  0.73097569  0.68385533]\n",
      "Best C is[ 0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/svm/base.py:898: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/svm/base.py:898: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV averages for values [0.0001, 0.00019, 0.00028000000000000003, 0.00037, 0.00046, 0.00055] are:[ 0.77849832  0.7683347   0.76560329  0.76094687  0.75321894  0.75034763]\n",
      "Best C is[ 0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV averages for values [9.999999999999999e-06, 3.7e-05, 6.4e-05, 9.099999999999999e-05, 0.000118, 0.000145] are:[ 0.78420387  0.78420387  0.78168751  0.77849832  0.776614    0.77407574]\n",
      "Best C is[  1.00000000e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV averages for values [0.0001, 8.47e-05, 6.94e-05, 5.410000000000001e-05, 3.880000000000001e-05, 2.35e-05] are:[ 0.77849832  0.7792029   0.77983196  0.78356121  0.78420387  0.78420387]\n",
      "Best C is[  3.88000000e-05]\n",
      "CV averages for values [4.6450000000000004e-05, 4.339e-05, 4.033e-05, 3.727e-05, 3.4210000000000006e-05, 3.1150000000000005e-05] are:[ 0.78356121  0.78235834  0.78420387  0.78420387  0.78420387  0.78420387]\n",
      "Best C is[  4.03300000e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "logitmodelInitSAPS,best_val = ajustLogisticRegression(patients_train,survived_train,patients_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=4.0330000000000002e-05, class_weight=None, dual=True,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=-1, penalty='l2', random_state=0,\n",
       "          solver='liblinear', tol=0.0001, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=best_val,\n",
    "                             fit_intercept=True, penalty='l2', \n",
    "                                                dual=True,  solver='liblinear',  n_jobs=-1, verbose=1, \n",
    "                                                random_state=0)\n",
    "model.fit(patients_train,survived_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression acurracy is 0.64\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression acurracy is %2.2f\" % accuracy_score(survived_test,model.predict(patients_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression acurracy is 0.64\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression acurracy is %2.2f\" % accuracy_score(survived_test,logitmodelInitSAPS.predict(patients_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aucModel(name,survived_test,model,patients_test):\n",
    "    logit_roc_auc = roc_auc_score(survived_test,model.predict(patients_test))\n",
    "    print(name+\" AUC = %2.2f\"% logit_roc_auc)\n",
    "    return logit_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "b'C <= 0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-174e43c07d8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                                                 \u001b[0mdual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                 random_state=0, max_iter=51200)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatients_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msurvived_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Logistic Regression acurracy is %2.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurvived_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatients_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlogit_roc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maucModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Logistic\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msurvived_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatients_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1231\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    891\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/svm/liblinear.pyx\u001b[0m in \u001b[0;36msklearn.svm.liblinear.train_wrap\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: b'C <= 0'"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2',C=int(best_val),class_weight=\"balanced\", \n",
    "                                                dual=True,  solver='liblinear',  \n",
    "                                                random_state=0, max_iter=51200)\n",
    "model.fit(patients_train,survived_train)\n",
    "print(\"Logistic Regression acurracy is %2.2f\" % accuracy_score(survived_test,model.predict(patients_test)))\n",
    "logit_roc_auc = aucModel(\"Logistic\",survived_test,model,patients_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logitmodelInitSAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression acurracy is %2.2f\" % accuracy_score(survived_test,logitmodelInitSAPS.predict(patients_test)))\n",
    "logit_roc_auc = aucModel(\"Logistic\",survived_test,model,patients_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
